{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from JetGraphProducer import JetGraphProducer\n",
    "import numpy as np, awkward as ak\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to calculate MT on the fly since the version with AK15 Jets is not stored in the ntuples. This will be loaded by the `JetGraphProducer` and ran event-by-event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mt(event):\n",
    "    \"\"\"\n",
    "    Calculates the transverse mass MT and RT (closely related calcs)\n",
    "    \"\"\"\n",
    "    met_x = np.cos(event.METPhi) * event.MET\n",
    "    met_y = np.sin(event.METPhi) * event.MET\n",
    "    jet_phi = event[\"JetsAK15/JetsAK15.fCoordinates.fPhi\"][1]\n",
    "    jet_pt = event[\"JetsAK15/JetsAK15.fCoordinates.fPt\"][1]\n",
    "    jet_e = event[\"JetsAK15/JetsAK15.fCoordinates.fE\"][1]\n",
    "    jet_x = np.cos(jet_phi) * jet_pt\n",
    "    jet_y = np.sin(jet_phi) * jet_pt\n",
    "    # jet_e = np.sqrt(jets.mass2 + jets.pt**2)\n",
    "    # m^2 + pT^2 = E^2 - pT^2 - pz^2 + pT^2 = E^2 - pz^2\n",
    "    pz = jet_pt * np.sinh(event[\"JetsAK15/JetsAK15.fCoordinates.fEta\"][1])\n",
    "    transverse_e = np.sqrt(jet_e**2 - pz**2)\n",
    "    mt = np.sqrt( (transverse_e + event.MET)**2 - (jet_x + met_x)**2 - (jet_y + met_y)**2 )\n",
    "\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the signal and background data as graphs. The frist time the data is loaded, the rootfiles are processed into `torch_geometric.data.InMemoryDataset` objects and also stored on diks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = JetGraphProducer(\n",
    "    \"test_data\",\n",
    "    n_store_jets=2,\n",
    "    use_lund_decomp=True,\n",
    "    n_lund_vars=5,\n",
    "    weights=\"xsec\",\n",
    "    extra_obs_to_load=[\"MET\", \"METPhi\"],\n",
    "    extra_obs_to_compute_per_event=[mt],\n",
    "    input_format=\"TreeMaker2\",\n",
    "    jet_collection=\"JetsAK15\",\n",
    "    verbose=True,\n",
    "    mask=True,\n",
    "    max_events_to_process=3000,\n",
    "    label=1.,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "background = JetGraphProducer(\n",
    "    \"test_data_bkg\",\n",
    "    n_store_jets=2,\n",
    "    use_lund_decomp=True,\n",
    "    n_lund_vars=5,\n",
    "    weights=\"xsec\",\n",
    "    extra_obs_to_load=[\"MET\", \"METPhi\"],\n",
    "    extra_obs_to_compute_per_event=[mt],\n",
    "    input_format=\"TreeMaker2\",\n",
    "    jet_collection=\"JetsAK15\",\n",
    "    verbose=True,\n",
    "    mask=True,\n",
    "    max_events_to_process=3000,\n",
    "    label=0.,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now preprocess the data by normalizing the node features and splitting it into training and testing, and merging them into one labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LundTreeUtilities import OnTheFlyNormalizer\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "signal_training = signal[::2][:int(len(signal)/2*0.8)]\n",
    "signal_testing = signal[::2][int(len(signal)/2*0.8):]\n",
    "\n",
    "background_training = background[:int(len(background)*0.8)]\n",
    "background_testing = background[int(len(background)*0.8):]\n",
    "\n",
    "weigths_signal_training = signal_training.w\n",
    "weigths_background_training = background_training.w\n",
    "weigths_signal_testing = signal_testing.w\n",
    "weigths_background_testing = background_testing.w\n",
    "\n",
    "means, stds = 0., 0.\n",
    "\n",
    "for graph in signal_training:\n",
    "    means += graph.x.sum(dim=0)*graph.w\n",
    "for graph in background_training:\n",
    "    means += graph.x.sum(dim=0)*graph.w\n",
    "for graph in signal_training:\n",
    "    stds += ((graph.x - means)**2).sum(dim=0)*graph.w\n",
    "for graph in background_training:\n",
    "    stds += ((graph.x - means)**2).sum(dim=0)*graph.w\n",
    "\n",
    "stds /= (signal_training.w.sum()+background_training.w.sum())\n",
    "stds = torch.sqrt(stds)\n",
    "\n",
    "# Careful that the normalizer is applied only once: slices in torch_geometric are actually only masks,\n",
    "# so _training and _testing objects share the same underlying tensor\n",
    "\n",
    "normalizer = OnTheFlyNormalizer([\"x\"], means, stds)\n",
    "normalizer(signal_training.data)\n",
    "normalizer(background_training.data)\n",
    "\n",
    "data_training = ConcatDataset((signal_training, background_training))\n",
    "data_testing = ConcatDataset((signal_testing, background_testing))\n",
    "weights = torch.cat((\n",
    "    weigths_signal_training/weigths_signal_training.sum(),\n",
    "    weigths_background_training/weigths_background_training.sum()\n",
    "    ))\n",
    "weights_testing = torch.cat((\n",
    "    weigths_signal_testing/weigths_signal_testing.sum(),\n",
    "    weigths_background_testing/weigths_background_testing.sum()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import LundNet\n",
    "\n",
    "# torch.set_num_threads(2)\n",
    "\n",
    "n_lund_vars = 5\n",
    "add_fractions = True\n",
    "num_classes = 1\n",
    "conv_params = [[32, 32], [32, 32], [64, 64], [64, 64], [128, 128], [128, 128]]\n",
    "fc_params = [(128, 0.8)]\n",
    "\n",
    "model = LundNet(\n",
    "    conv_params=conv_params,\n",
    "    fc_params=fc_params,\n",
    "    input_dims=n_lund_vars,\n",
    "    use_fusion=True,\n",
    "    num_classes=num_classes,\n",
    "    add_fractions_to_lund=add_fractions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "sampler = WeightedRandomSampler(weights/weights.sum(), len(data_training), replacement=True)\n",
    "loader = DataLoader(data_training, batch_size=128, sampler=sampler)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 5\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch in tqdm(loader, desc=f\"Training epoch {epoch}\", leave=False):\n",
    "        y_pred = model(batch)\n",
    "        loss = torch.nn.BCELoss()(y_pred[:,0], batch.y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Training step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_testing = WeightedRandomSampler(\n",
    "    weights_testing/weights_testing.sum(),\n",
    "    len(data_testing),\n",
    "    replacement = True\n",
    ")\n",
    "\n",
    "loader_testing = DataLoader(data_testing, sampler=sampler_testing, batch_size=len(data_testing))\n",
    "\n",
    "scores_testing = []\n",
    "labels_testing = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader_testing:\n",
    "        scores_testing.append(model(batch))\n",
    "        labels_testing.append(batch.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_testing = scores_testing[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr, tpr, _ = roc_curve(labels_testing[0], scores_testing)\n",
    "auc = roc_auc_score(labels_testing[0], scores_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, label=f\"ROC AUC: {auc:.3f}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"fpr\")\n",
    "plt.ylabel(\"tpr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scores_testing[labels_testing[0] == 1.], label=\"Signal\")\n",
    "plt.hist(scores_testing[labels_testing[0] == 0.], label=\"Background\")\n",
    "plt.xlabel(\"LundNET score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
